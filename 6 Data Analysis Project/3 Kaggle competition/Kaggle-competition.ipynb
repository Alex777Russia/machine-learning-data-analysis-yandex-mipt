{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "\n",
    "#vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#gridsearch\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "#classifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "\n",
    "#words\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_to_string(*args, **kwargs):\n",
    "    output = io.StringIO()\n",
    "    print(*args, file=output, **kwargs)\n",
    "    contents = output.getvalue()\n",
    "    output.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соревнование по сентимент-анализу\n",
    "В этом соревновании вам предстоит прогнозировать по тексту отзыва его тональность: 1 - позитивная, 0 - негативная. В отличие от усложненной версии задачи, здесь вам не требуется самостоятельно собирать обучающую выборку - она есть в предоставляемых вам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке на каждой строчке дано по одному тексту с классом (0 или 1), записанным через символ табуляции после текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/products_sentiment_train.tsv', sep = '\\t', header = None, names = ['text', 'class'])\n",
    "df_test = pd.read_csv('data/products_sentiment_test.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   0  so , why the small digital elph , rather than ...\n",
       "1   1  3/4 way through the first disk we played on it...\n",
       "2   2  better for the zen micro is outlook compatibil...\n",
       "3   3    6 . play gameboy color games on it with goboy .\n",
       "4   4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов в обучающей выборке  2000\n",
      "Количество объектов в тестовой выборке  500\n",
      "Количество неуникальных слов 39512\n",
      "Среднее количество слов в документе 19.756\n",
      "Количество уникальных слов 3973\n",
      "Количество объектов класса 1 к количеству объектов в обучающей выборке равно  0.637\n"
     ]
    }
   ],
   "source": [
    "print('Количество объектов в обучающей выборке ', len(df_train))\n",
    "print('Количество объектов в тестовой выборке ', len(df_test))\n",
    "print('Количество неуникальных слов', sum(df_train['text'].str.split().apply(len)))\n",
    "print('Среднее количество слов в документе', sum(df_train['text'].str.split().apply(len))/len(df_train))\n",
    "print('Количество уникальных слов', TfidfVectorizer().fit_transform(df_train.text).shape[1])\n",
    "print('Количество объектов класса 1 к количеству объектов в обучающей выборке равно ', sum(df_train['class'])/len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как будем обучать\n",
    "Нам дали обучающую выборку с классами и тестовую без классов. Чтобы избежать переобучения, мы используем кросс валидацию на обучающей выборке. Согласно некоторой метрике (в рамках этой задачи accuracy) получаем самую лучшую модель, выбранную с помощью grid search и/или личных соображений/предпочтений. Чем больше качество на обучающей по вышеуказанному алгоритму, тем лучше оценка на тестовой выборке - по крайней мере после нескольких моих самбитов зависимость виднеется. \n",
    "\n",
    "В качестве метрики качества используется accuracy. При валидации качества не забывайте, что ваш результат точно должен быть лучше, чем тривиальные ответы (всегда 0, всегда 1, случайный выбор класса).\n",
    "\n",
    "Особенности тестовой выборки мы не знаем - лишь предполагаем, что она похожа на обучающую выборку. Поэтому это зпдание чем-то похоже в игру в слепую)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search - немного бездумный способ, который стоит применять с осторожностью\n",
    "Не рекомендую на малом количестве данных, так как возможно *слегка* переобучиться 😢 Плюс из-за огромного количества параметров не особо удобно анализировать, от какого параметра изменяется метрика\n",
    "\n",
    "### Создадим классы-обертки для удобной работы в pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass\n",
    "\n",
    "class Doc2VecModel(BaseEstimator):\n",
    "    def __init__(self, dm=1, vector_size=20, window=5, hs = 1, min_count = 5, epochs = 5, stop_words = None):\n",
    "        self.d2v_model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.dm = dm\n",
    "        self.hs = hs\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.stop_words = stop_words\n",
    "\n",
    "    def fit(self, raw_documents, y=None):\n",
    "        # Initialize model\n",
    "        self.d2v_model = Doc2Vec(vector_size=self.vector_size, \n",
    "                                window=self.window, \n",
    "                                dm=self.dm,\n",
    "                                hs = self.hs,\n",
    "                                min_count = self.min_count,\n",
    "                                epochs = self.epochs)\n",
    "        # Tag docs\n",
    "        tagged_documents = []\n",
    "        for index, row in raw_documents.iteritems():\n",
    "            tag = '{}_{}'.format(\"type\", index)\n",
    "            tokens = row.split()\n",
    "            if self.stop_words is not None:\n",
    "                tokens = [word for word in tokens if word not in self.stop_words]\n",
    "            tagged_documents.append(TaggedDocument(words=tokens, tags=[tag]))\n",
    "        # Build vocabulary\n",
    "        self.d2v_model.build_vocab(tagged_documents)\n",
    "        # Train model\n",
    "        self.d2v_model.train(tagged_documents, total_examples=len(tagged_documents), epochs=self.d2v_model.iter)\n",
    "        return self\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        X = []\n",
    "        for index, row in raw_documents.iteritems():\n",
    "            row = row.split()\n",
    "            X.append(self.d2v_model.infer_vector(row))\n",
    "        X = pd.DataFrame(X, index=raw_documents.index)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "        self.fit(raw_documents)\n",
    "        return self.transform(raw_documents)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим мега подборку параметров сетки, чтобы компьютер сгорел 🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = np.arange(1,11)\n",
    "ngram_range = list(combinations_with_replacement(comb, 2))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect\n",
    "vect_param_grid = {\n",
    "    'vect': [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vect__min_df': np.arange(0.0, 1.1, 0.2),\n",
    "    'vect__max_df': np.arange(0.0, 1.1, 0.2),\n",
    "    'vect__ngram_range': ngram_range,\n",
    "    'vect__stop_words': ['english', stopwords.words('english'), get_stop_words('en'), None],\n",
    "    'vect__analyzer': ['word', 'char', 'char_wb']   \n",
    "}\n",
    "hashing_vect_param_grid = {\n",
    "    'vect': [HashingVectorizer()],\n",
    "    'vect__ngram_range': ngram_range,\n",
    "    'vect__stop_words': ['english', stopwords.words('english'), get_stop_words('en'), None],\n",
    "    'vect__analyzer': ['word', 'char', 'char_wb']   \n",
    "}\n",
    "doc2vec_param_grid = {\n",
    "    'vect': [Doc2VecModel()],\n",
    "    'vect__epochs': [1, 3, 5],\n",
    "    'vect__hs': [0, 1],\n",
    "    'vect__vector_size': [1, 10, 50, 100],\n",
    "    'vect__dm':[0,1],\n",
    "    'vect__window': np.arange(1,10,2),\n",
    "    'vect__min_count': [0, 50, 100, 2000],\n",
    "    'vect__stop_words': [stopwords.words('english'), get_stop_words('en'), None]\n",
    "}\n",
    "\n",
    "#clf\n",
    "linear_param_grid = {\n",
    "    'clf' : [LogisticRegression(), SGDClassifier(), RidgeClassifier()]\n",
    "}\n",
    "naive_param_grid = {\n",
    "    'clf': [BernoulliNB(), CategoricalNB(), ComplementNB(), GaussianNB(), MultinomialNB()]\n",
    "}\n",
    "neighbors_param_grid = {\n",
    "    'clf': [KNeighborsClassifier()]\n",
    "}\n",
    "forest_param_grid = {\n",
    "    'clf': [RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "}\n",
    "linear_svc_param_grid = {\n",
    "    'clf':[LinearSVC()],\n",
    "    'clf__loss': ['hinge', 'squared_hinge'],\n",
    "    'clf__multi_class': ['ovr', 'crammer_singer'],\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "    'clf__penalty': ['l1', 'l2']\n",
    "}\n",
    "svc_param_grid = {\n",
    "    'clf':[SVC()],\n",
    "    'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "    'clf__class_weight': ['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    vect_param_grid,\n",
    "    hashing_vect_param_grid,\n",
    "    doc2vec_param_grid,\n",
    "    \n",
    "    linear_param_grid,\n",
    "    naive_param_grid,\n",
    "    neighbors_param_grid,\n",
    "    forest_param_grid,\n",
    "    linear_svc_param_grid,\n",
    "    svc_param_grid\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем долгий поиск по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11677 candidates, totalling 58385 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1722 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2512 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3186 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3936 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5340 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6408 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7458 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8608 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9858 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11208 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12658 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14208 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 15858 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 17608 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 19458 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 21408 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 23684 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 27560 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done 30490 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 32840 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done 35290 tasks      | elapsed: 67.2min\n",
      "[Parallel(n_jobs=-1)]: Done 37840 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=-1)]: Done 40490 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 43240 tasks      | elapsed: 81.1min\n",
      "[Parallel(n_jobs=-1)]: Done 46090 tasks      | elapsed: 90.2min\n",
      "[Parallel(n_jobs=-1)]: Done 49040 tasks      | elapsed: 102.8min\n",
      "[Parallel(n_jobs=-1)]: Done 52090 tasks      | elapsed: 115.6min\n",
      "[Parallel(n_jobs=-1)]: Done 55240 tasks      | elapsed: 131.0min\n",
      "[Parallel(n_jobs=-1)]: Done 58385 out of 58385 | elapsed: 148.7min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('vect', Doc2VecModel(vector_size = 1)), ('clf', LinearSVC(class_weight = None))])\n",
    "search = GridSearchCV(pipe, param_grid, verbose = 1, scoring = 'accuracy', n_jobs=-1, cv = 5)\n",
    "search = search.fit(df_train['text'], df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(search, message = None):\n",
    "    info = re.sub(' +', ' ',print_to_string('vect\\n',search.best_estimator_['vect'], \n",
    "                                            '\\nclf\\n', search.best_estimator_['clf'],\n",
    "                                            '\\nscore\\n', search.best_score_)\n",
    "                 )\n",
    "    print(info)\n",
    "    \n",
    "    message = '' if message is None else message + ' '\n",
    "    name = message + str(search.best_score_) + ' ' + type(search.best_estimator_['vect']).__name__ + ' ' + type(search.best_estimator_['clf']).__name__\n",
    "    \n",
    "    df_test['y'] = pd.DataFrame(search.best_estimator_.predict(df_test['text']))\n",
    "    \n",
    "    df_test[['Id', 'y']].to_csv('results/' + name + '.csv', index=False)\n",
    "    with open('results/' + name + '.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect\n",
      " TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
      " dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      " input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      " min_df=0.0, ngram_range=(1, 10), norm='l2', preprocessor=None,\n",
      " smooth_idf=True, stop_words='english', strip_accents=None,\n",
      " sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " tokenizer=None, use_idf=True, vocabulary=None) \n",
      "clf\n",
      " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      " intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      " multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      " verbose=0) \n",
      "score\n",
      " 0.7999999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты\n",
    "* Возможно переобучение. ngram_range получился сишком большим 1-10 слов, а чем больше этот диапозон, тем больше переобуечния. Поэтому оценка на тестовой выборке получилась 0.80444.\n",
    "* Doc2Vec не справляется. Получилось добиться малой точности на обучающей выборке - 0.666. Этой модели банально не хватает данных - нейронная сеть DocVec не предназначена для таких маленьких выборок.\n",
    "* Случайный лес и градиентный бустинг работают долго в силу своей специфики, но дают не такое хорошее качество, как простой и быстрый LinearSVC.\n",
    "* TfidfVectorizer лучше CountVectorizer за счёт того, что вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что плохого в grid search?\n",
    "* Поиск по сетке ищет самое лучшее значение метрики, перебирая все возможные сочетания параметров. Это может привести к переообучению (кросс-валидация может ослабить переобучение, но оно возможно). \n",
    "* Неудобно анализировать, какие именно параметры вносят вклад - их много."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Самостоятельный поиск \n",
    "В предыдущем примере было обнаружено, что самое лучшее значение даёт TfidfVectorizer, LinearSVC, LogisticRegression - попробуем развить идею."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vect': [TfidfVectorizer()],\n",
    "    'vect__ngram_range': ngram_range,\n",
    "    'clf':[LinearSVC(),LogisticRegression()],    \n",
    "    'clf__C': np.arange(0.6, 1.7 ,0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('vect', TfidfVectorizer(ngram_range = [1,6])), ('clf', LinearSVC(C=1.0))])\n",
    "search = GridSearchCV(pipe, param_grid, verbose = 1, scoring = 'accuracy', n_jobs=-1, cv = 5)\n",
    "search = search.fit(df_train['text'], df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect\n",
      " TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      " dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      " input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      " min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      " smooth_idf=True, stop_words=None, strip_accents=None,\n",
      " sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " tokenizer=None, use_idf=True, vocabulary=None) \n",
      "clf\n",
      " LinearSVC(C=1.4000000000000004, class_weight=None, dual=True,\n",
      " fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      " max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      " tol=0.0001, verbose=0) \n",
      "score\n",
      " 0.7915000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на тестовой выборке этих параметров дала 0.81111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'clf': LinearSVC(C=1.4000000000000004, class_...</td>\n",
       "      <td>0.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'clf': LinearSVC(C=1.4000000000000004, class_...</td>\n",
       "      <td>0.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'clf': LinearSVC(C=1.4000000000000004, class_...</td>\n",
       "      <td>0.7830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'clf': LinearSVC(C=1.4000000000000004, class_...</td>\n",
       "      <td>0.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'clf': LinearSVC(C=1.4000000000000004, class_...</td>\n",
       "      <td>0.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight...</td>\n",
       "      <td>0.7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight...</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight...</td>\n",
       "      <td>0.7085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight...</td>\n",
       "      <td>0.7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>{'clf': LogisticRegression(C=1.0, class_weight...</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params   score\n",
       "0    {'clf': LinearSVC(C=1.4000000000000004, class_...  0.7700\n",
       "1    {'clf': LinearSVC(C=1.4000000000000004, class_...  0.7850\n",
       "2    {'clf': LinearSVC(C=1.4000000000000004, class_...  0.7830\n",
       "3    {'clf': LinearSVC(C=1.4000000000000004, class_...  0.7780\n",
       "4    {'clf': LinearSVC(C=1.4000000000000004, class_...  0.7700\n",
       "..                                                 ...     ...\n",
       "115  {'clf': LogisticRegression(C=1.0, class_weight...  0.7230\n",
       "116  {'clf': LogisticRegression(C=1.0, class_weight...  0.7170\n",
       "117  {'clf': LogisticRegression(C=1.0, class_weight...  0.7085\n",
       "118  {'clf': LogisticRegression(C=1.0, class_weight...  0.7070\n",
       "119  {'clf': LogisticRegression(C=1.0, class_weight...  0.7035\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {'params': search.cv_results_['params'],\n",
    "    'score': search.cv_results_['mean_test_score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Через несколько самбитов удалось добиться точности 0.82000 на тестовой выборке с такими параметрами:\n",
    "* TfidfVectorizer(ngram_range = `[1,6`])\n",
    "* LinearSVC(C = 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличим обучающую выборку\n",
    "Схитрим. Увеличим выборку, добавив тестовую выборку, которую разметили алгоритмом выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2500 non-null   object\n",
      " 1   class   2500 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 58.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_and_test = df_train.append(df_test[['text','y']].rename(columns={\"y\": \"class\"}))\n",
    "df_train_and_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('vect', TfidfVectorizer(ngram_range = [1,6])), ('clf', LinearSVC(C = 1.1))])\n",
    "param_grid = {'vect': [TfidfVectorizer(ngram_range = [1,6])], 'clf': [LinearSVC(C = 1.1)]}\n",
    "search = GridSearchCV(pipe, param_grid, verbose = 1, scoring = 'accuracy', n_jobs=-1, cv = 5)\n",
    "search = search.fit(df_train_and_test['text'], df_train_and_test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vect\n",
      " TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      " dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      " input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      " min_df=1, ngram_range=[1, 6], norm='l2', preprocessor=None,\n",
      " smooth_idf=True, stop_words=None, strip_accents=None,\n",
      " sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      " tokenizer=None, use_idf=True, vocabulary=None) \n",
      "clf\n",
      " LinearSVC(C=1.1, class_weight=None, dual=True, fit_intercept=True,\n",
      " intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      " multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      " verbose=0) \n",
      "score\n",
      " 0.8132000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_result(search, 'df_train_and_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на тестовой выборке стала хуже - 0.8066. То есть добавление не очень правильно размеченной выборки к обучающей выборке не добавляет качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "* выборка маленькая, из-за чего получить качество больше 80% сложновато.\n",
    "* текст в датасете содержит грамматические ошибки, лишние символы, ошибки в построении предложений. Иногда встречаются нейтральные отзывы. Сама выборка не такая хорошая, как хотелось бы.\n",
    "* данное соревнование больше походило на игру вслепую - мы стараемся добиться качества на тестовой выборке, зная лишь небольшой объём обучающей выборки. Из-за этого иногда качество на обучающей выборке не всегда равнялось качеству на тестовой - отклонения доходили до 2-4% в ту или иную сторону. Но всё равно чем больше было качество по кросс-валидации на обучающей выборке, тем больше было качество на тестовой (с некоторыми отклонениями от качества на обучающей).\n",
    "* лучшим вариантом на таким объёмах является TFIDFVectorizer + LogisticRegression или LineraSVC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
