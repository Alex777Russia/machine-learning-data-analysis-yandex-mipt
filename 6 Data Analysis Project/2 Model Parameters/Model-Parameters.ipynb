{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка параметров\n",
    "В этом задании вам предстоит поэкспериментировать с параметрами вашей модели для сентимент-анализа. Все задания выполняются на том же датасете, что и на прошлой неделе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "negfeats = [\" \".join(movie_reviews.words(fileids=[f])) for f in negids]\n",
    "posfeats = [\" \".join(movie_reviews.words(fileids=[f])) for f in posids]\n",
    "reviews = negfeats + posfeats\n",
    "\n",
    "neg_classes = [0] * len(negids)\n",
    "pos_classes = [1] * len(posids)\n",
    "classes = neg_classes + pos_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_to_file(value, name):\n",
    "    print(name, value)\n",
    "    with open(name, \"w\") as file:\n",
    "        file.write(str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество ( .mean() ) и стандартное отклонение ( .std() ) по fold'ам для: \n",
    "\n",
    "    а) pipeline из CountVectorizer() и LogisticRegression(), \n",
    "\n",
    "    б) pipeline из TfidfVectorizer() и LogisticRegression(). \n",
    "\n",
    "В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipe_scores(vectorizer, clf):\n",
    "    count_pipe = Pipeline([('vectorizer', vectorizer), ('clf', clf)])\n",
    "    return cross_val_score(count_pipe, reviews, classes, cv = 5)\n",
    "def get_str_list(lst):\n",
    "    return ' '.join(list(map(str, lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt 0.841 0.01677796173556255 0.8210000000000001 0.004062019202317978\n"
     ]
    }
   ],
   "source": [
    "count_scores = get_pipe_scores(CountVectorizer(), LogisticRegression(solver='liblinear'))\n",
    "tfidf_scores = get_pipe_scores(TfidfVectorizer(), LogisticRegression(solver='liblinear'))\n",
    "means_stds = get_str_list([count_scores.mean(), count_scores.std(), tfidf_scores.mean(), tfidf_scores.std()])\n",
    "print_to_file(means_stds, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Попробуйте задавать разные значения параметра min_df у CountVectorizer. Оцените качество вашего классификатора с min_df=10 и с min_df=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.txt 0.8390000000000001 0.8155000000000001\n"
     ]
    }
   ],
   "source": [
    "min_df_10_scores = get_pipe_scores(CountVectorizer(min_df=10), LogisticRegression(solver='liblinear'))\n",
    "min_df_50_scores = get_pipe_scores(TfidfVectorizer(min_df=50), LogisticRegression(solver='liblinear'))\n",
    "min_df_means = get_str_list([min_df_10_scores.mean(), min_df_50_scores.mean()])\n",
    "print_to_file(min_df_means, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Попробуйте использовать разные классификаторы после CountVectorizer. И vectorizer, и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.txt 0.74\n"
     ]
    }
   ],
   "source": [
    "clfs = [LogisticRegression(solver='liblinear'), LinearSVC(), SGDClassifier(random_state=42)] \n",
    "# SGDClassifier каждый раз будет давать разные результаты, поэтому лучше зафиксировать random_state для грейдера \n",
    "means = []\n",
    "for clf in clfs:\n",
    "    mean = get_pipe_scores(CountVectorizer(), clf).mean()\n",
    "    means.append(mean)\n",
    "print_to_file(min(means), '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.txt 0.8414999999999999 0.8390000000000001\n"
     ]
    }
   ],
   "source": [
    "nltk_stop_scores = get_pipe_scores(CountVectorizer(stop_words = stopwords.words('english')), \n",
    "                                   LogisticRegression(solver='liblinear'))\n",
    "sklrn_stop_scores = get_pipe_scores(CountVectorizer(stop_words = 'english'), \n",
    "                                   LogisticRegression(solver='liblinear'))\n",
    "stop_means = get_str_list([nltk_stop_scores.mean(), sklrn_stop_scores.mean()])\n",
    "print_to_file(stop_means, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.txt 0.8525 0.82\n"
     ]
    }
   ],
   "source": [
    "vectorizers = [CountVectorizer(ngram_range = [1,2]),\n",
    "               CountVectorizer(ngram_range = [3,5], analyzer='char_wb')]\n",
    "means = []\n",
    "for vectorizer in vectorizers:\n",
    "    mean = get_pipe_scores(vectorizer, LogisticRegression(solver='liblinear')).mean()\n",
    "    means.append(mean)\n",
    "ngram_means = get_str_list(means)\n",
    "print_to_file(ngram_means, '5.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
